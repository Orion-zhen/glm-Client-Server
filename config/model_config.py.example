LLM_ROOT_DIR = "/home/orion/ai/Models"

LLM = "Qwen-14B-Chat"

LLM_CARD = {
    "chatglm3-6b":
        {
            "path": "chatglm3-6b",
            "params": [],
        },
    "WizardLM-7B-uncensored":
        {
            "path": "WizardLM-7B-uncensored-GPTQ",
            "params": ["--enable-exllama"],
        },
    "Qwen-14B-Chat":
        {
            "path": "Qwen-14B-Chat-GPTQ",
            "params": [],
            "note": "不能开exllama, cpu版可以试用xfastertransformer"
        },
    "OrionStar-Yi-34B":
        {
            "path": "OrionStar-Yi-34B-Chat-Llama-GPTQ",
            "params": ["--enable-exllama"],
            "note": "效果不行, 开了exllama就说个不停, 不开就跑不了; 能力也没qwen强"
        }
}